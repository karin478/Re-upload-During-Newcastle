{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19591,"status":"ok","timestamp":1659258641759,"user":{"displayName":"B Hank","userId":"15763974084442005842"},"user_tz":-60},"id":"717WXX13D_ui","outputId":"f762fca5-0de5-47d3-faf0-a403768829d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161885,"status":"ok","timestamp":1659258806005,"user":{"displayName":"B Hank","userId":"15763974084442005842"},"user_tz":-60},"id":"4esUpMISqPZJ","outputId":"92eb0227-da9d-4084-a0a9-5d1a650cb16c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["True\n","The number of training 3995, validation 999 \n","Found 50422 unique words: \n","data shape:  (4994, 500)\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Thu Jul 28 10:01:20 2022\n","\n","@author: karin\n","\"\"\"\n","\n","#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Jul 27 10:57:03 2022\n","\n","@author: lvbinghan\n","\"\"\"\n","\n","#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Jul  9 21:43:53 2022\n","\n","@author: lvbinghan\n","\"\"\"\n","\n","# importing system libraries\n","\n","from os import walk\n","from string import punctuation\n","from random import shuffle\n","from collections import Counter\n","from sklearn.model_selection import cross_val_predict\n","# importing additional libraries\n","\n","import pandas as pd\n","import sklearn as sk\n","import nltk\n","import pytest\n","\n","\n","nltk.download('stopwords')\n","\n","\n","from nltk.test.classify_fixt import setup_module\n","setup_module()\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import collections\n","\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import warnings\n","warnings.simplefilter(action='ignore', category=Warning)\n","import keras\n","from keras.layers import Dense, Embedding, LSTM, Dropout\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import pickle\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Read the whole data from the Enron Dataset into a variable allData.\n","\n","pathwalk = walk(r\"/content/gdrive/MyDrive/enron1/\")\n","\n","allHamData, allSpamData = [], []\n","for root, dr, file in pathwalk:\n","    if 'ham' in str(file):\n","        for obj in file:\n","            with open(root + '/' + obj, encoding='latin1') as ip:\n","                allHamData.append(\" \".join(ip.readlines()))\n","                \n","    elif 'spam' in str(file):\n","        for obj in file:\n","            with open(root + '/' + obj, encoding='latin1') as ip:\n","                allSpamData.append(\" \".join(ip.readlines()))\n","                \n","                \n","                \n","\n","allHamData = list(set(allHamData))\n","allSpamData = list(set(allSpamData))\n","\n","\n","hamPlusSpamData = allHamData + allSpamData\n","labels = [\"ham\"]*len(allHamData) + [\"spam\"]*len(allSpamData)\n","\n","raw_df = pd.DataFrame({\"email\": hamPlusSpamData, \n","                       \"label\": labels})\n","\n","\n","\n","raw_df.sample(5)\n","raw_df['email']\n","\n","\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","\n","\n","def preprocess(data):\n","    # tokenization\n","    tokens = nltk.word_tokenize(data)\n","    tokens = [w.lower() for w in tokens if w.isalpha()]\n","\n","    # finding uncommon words\n","    cnt = Counter(tokens)\n","    uncommons = cnt.most_common()[:-int(len(cnt)*0.1):-1]\n","    \n","    # listing stopwords from NLTK\n","    stops = set(nltk.corpus.stopwords.words('english'))\n","\n","    # removing stop words and uncommon words\n","    tokens = [w for w in tokens if (w not in stops and w not in uncommons)]\n","\n","    # lemmatization\n","    lemmatizer = nltk.WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(w, pos='a') for w in tokens]\n","\n","    return tokens\n","\n","label_encoder = sk.preprocessing.LabelEncoder()\n","raw_df['label'] = label_encoder.fit_transform(raw_df.label)\n","import string\n","from nltk.corpus import stopwords\n","\n","def process_text(text):\n","    no_punc = [char for char in text if char not in string.punctuation]\n","    no_punc = ''.join(no_punc)\n","    return ' '.join([word for word in no_punc.split() if word.lower() not in stopwords.words('english')])\n","\n","raw_df['email']=raw_df['email'].apply(process_text)\n","raw_df['email']\n","\n","from nltk.stem import PorterStemmer\n","stemmer = PorterStemmer()\n","def stemming (text):\n","    return ''.join([stemmer.stem(word) for word in text])\n","raw_df['email']=raw_df['email'].apply(stemming)\n","raw_df.head()\n","\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer= CountVectorizer()\n","message_bow = vectorizer.fit_transform(raw_df['email'])\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(message_bow,raw_df['label'],test_size=0.25)\n","\n","X = message_bow\n","y = raw_df['label']\n","\n","\n","\n","\n","# TF-IDF\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","tfidf_transformer = TfidfTransformer().fit(message_bow)\n","\n","# Transform entire BoW into tf-idf corpus\n","message_bow_tfidf = tfidf_transformer.transform(message_bow)\n","\n","X_tfidf = message_bow_tfidf\n","y = raw_df['label']\n","X_tfidf_train,X_tfidf_test,y_tfidf_train,y_tfidf_test = train_test_split(message_bow_tfidf,raw_df['label'],test_size=0.25)\n","\n","\n","\n","texts1 = np.asarray(message_bow)\n","labels1 = np.asarray(raw_df['label'])\n","\n","\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","\n","from keras.layers import SimpleRNN, Embedding, Dense, LSTM\n","from keras.models import Sequential\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# number of words used as features\n","max_features = 500000\n","# cut off the words after seeing 500 words in each document(email)\n","maxlen = 500\n","\n","\n","# we will use 80% of data as training, 20% as validation data\n","training_samples = int(4994 * .8)\n","validation_samples = int(4994 - training_samples)\n","# sanity check\n","print(len(raw_df['email']) == (training_samples + validation_samples))\n","print(\"The number of training {0}, validation {1} \".format(training_samples, validation_samples))\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(raw_df['email'])\n","sequences = tokenizer.texts_to_sequences(raw_df['email'])\n","\n","word_index = tokenizer.word_index\n","print(\"Found {0} unique words: \".format(len(word_index)))\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","\n","print(\"data shape: \", data.shape)\n","\n","np.random.seed(42)\n","# shuffle data\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = np.asarray(labels)\n","labels = y[indices]\n","\n","\n","texts_train = data[:training_samples]\n","y_train = labels[:training_samples]\n","texts_test = data[training_samples:]\n","y_test = labels[training_samples:]\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19655,"status":"ok","timestamp":1659258930461,"user":{"displayName":"B Hank","userId":"15763974084442005842"},"user_tz":-60},"id":"dEC4fJZkqJju","outputId":"af2f1f17-8606-4506-8fff-29547480c468"},"outputs":[{"output_type":"stream","name":"stdout","text":["400/400 [==============================] - 14s 17ms/step - loss: 0.2141 - acc: 0.9076\n","32/32 [==============================] - 1s 9ms/step - loss: 0.0607 - acc: 0.9830\n","Test loss is 0.0607 accuracy is 0.9830  \n","LSTM score               precision    recall  f1-score   support\n","\n","           0     0.9916    0.9847    0.9881       718\n","           1     0.9615    0.9786    0.9700       281\n","\n","    accuracy                         0.9830       999\n","   macro avg     0.9766    0.9817    0.9791       999\n","weighted avg     0.9831    0.9830    0.9830       999\n","\n","[[707   6]\n"," [ 11 275]]\n"]}],"source":["max_features =500000\n","model = Sequential()\n","model.add(Embedding(max_features, 32))\n","model.add(LSTM(32))\n","model.add(Dense(32, activation='relu'))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","history_ltsm = model.fit(texts_train, y_train, epochs=1, batch_size=10)\n","\n","pred = (model.predict(texts_test) > 0.5).astype(\"int32\")\n","\n","acc = model.evaluate(texts_test, y_test)\n","proba_ltsm = (model.predict(texts_test) > 0.5).astype(\"int32\")\n","from sklearn.metrics import confusion_matrix\n","print(\"Test loss is {0:.4f} accuracy is {1:.4f}  \".format(acc[0],acc[1]))\n","\n","from sklearn.metrics import classification_report\n","print(\"LSTM score\",classification_report(y_test,pred, digits=4))\n","print(confusion_matrix(pred, y_test))\n"]},{"cell_type":"markdown","metadata":{"id":"Cplk3-5EyLrw"},"source":["512 单层 bach=10 epoch=10 98.0\n","512 单层 bach=10 epoch=12 96.3\n","512 单层 bach=10 epoch=10 + dense512  98.2\n","512 单层 bach=10 epoch=10 + dense256  97.5\n","512 单层 bach=8 epoch=10 + dense512  98.0\n","512 单层 bach=12 epoch=10 + dense512  98.6\n","512 单层 bach=14 epoch=10 + dense512  96.7\n","512 单层 bach=11 epoch=10 + dense512  97.7\n","512 单层 bach=12 epoch=20 + dense512  98.1\n","1024 单层 bach=12 epoch=20 + dense1024  98.2\n","1024 单层 bach=8 epoch=20 + dense1024  98.4\n","1024 单层 bach=6 epoch=20 + dense1024  98.1\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn8Fb-d0EQaI","executionInfo":{"status":"ok","timestamp":1659271043635,"user_tz":-60,"elapsed":382600,"user":{"displayName":"B Hank","userId":"15763974084442005842"}},"outputId":"6e4c52d6-fee0-483f-d989-915d1dd44eb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","32/32 [==============================] - 6s 87ms/step - loss: 0.5434 - acc: 0.7519\n","Epoch 2/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0985 - acc: 0.9660\n","Epoch 3/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0324 - acc: 0.9887\n","Epoch 4/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0787 - acc: 0.9817\n","Epoch 5/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0154 - acc: 0.9960\n","Epoch 6/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0084 - acc: 0.9975\n","Epoch 7/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0050 - acc: 0.9982\n","Epoch 8/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0035 - acc: 0.9990\n","Epoch 9/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0026 - acc: 0.9990\n","Epoch 10/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0016 - acc: 0.9995\n","Epoch 11/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0040 - acc: 0.9992\n","Epoch 12/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0011 - acc: 0.9995\n","Epoch 13/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0035 - acc: 0.9995\n","Epoch 14/20\n","32/32 [==============================] - 3s 88ms/step - loss: 7.8612e-04 - acc: 0.9997\n","Epoch 15/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0011 - acc: 0.9997\n","Epoch 16/20\n","32/32 [==============================] - 3s 88ms/step - loss: 3.0519e-04 - acc: 0.9997\n","Epoch 17/20\n","32/32 [==============================] - 3s 88ms/step - loss: 2.3717e-04 - acc: 1.0000\n","Epoch 18/20\n","32/32 [==============================] - 3s 88ms/step - loss: 1.1417e-04 - acc: 1.0000\n","Epoch 19/20\n","32/32 [==============================] - 3s 88ms/step - loss: 5.3384e-04 - acc: 0.9997\n","Epoch 20/20\n","32/32 [==============================] - 3s 88ms/step - loss: 3.5905e-05 - acc: 1.0000\n","Epoch 1/20\n","32/32 [==============================] - 6s 87ms/step - loss: 0.3154 - acc: 0.8493\n","Epoch 2/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0654 - acc: 0.9795\n","Epoch 3/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0481 - acc: 0.9880\n","Epoch 4/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0366 - acc: 0.9927\n","Epoch 5/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0573 - acc: 0.9870\n","Epoch 6/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0327 - acc: 0.9925\n","Epoch 7/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0082 - acc: 0.9982\n","Epoch 8/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0035 - acc: 0.9985\n","Epoch 9/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0065 - acc: 0.9980\n","Epoch 10/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0022 - acc: 0.9992\n","Epoch 11/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0140 - acc: 0.9980\n","Epoch 12/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0014 - acc: 0.9995\n","Epoch 13/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0016 - acc: 0.9995\n","Epoch 14/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0011 - acc: 0.9995\n","Epoch 15/20\n","32/32 [==============================] - 3s 89ms/step - loss: 9.3181e-04 - acc: 0.9997\n","Epoch 16/20\n","32/32 [==============================] - 3s 89ms/step - loss: 7.3025e-04 - acc: 0.9995\n","Epoch 17/20\n","32/32 [==============================] - 3s 89ms/step - loss: 5.4206e-04 - acc: 1.0000\n","Epoch 18/20\n","32/32 [==============================] - 3s 89ms/step - loss: 2.5690e-04 - acc: 1.0000\n","Epoch 19/20\n","32/32 [==============================] - 3s 89ms/step - loss: 3.6478e-04 - acc: 0.9997\n","Epoch 20/20\n","32/32 [==============================] - 3s 89ms/step - loss: 1.2382e-04 - acc: 1.0000\n","Epoch 1/20\n","32/32 [==============================] - 6s 87ms/step - loss: 0.4875 - acc: 0.7660\n","Epoch 2/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0986 - acc: 0.9657\n","Epoch 3/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0353 - acc: 0.9892\n","Epoch 4/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0193 - acc: 0.9950\n","Epoch 5/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0095 - acc: 0.9965\n","Epoch 6/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0072 - acc: 0.9982\n","Epoch 7/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0071 - acc: 0.9982\n","Epoch 8/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0037 - acc: 0.9987\n","Epoch 9/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0090 - acc: 0.9982\n","Epoch 10/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0015 - acc: 0.9995\n","Epoch 11/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0016 - acc: 0.9990\n","Epoch 12/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0023 - acc: 0.9992\n","Epoch 13/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0067 - acc: 0.9992\n","Epoch 14/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0015 - acc: 0.9995\n","Epoch 15/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0067 - acc: 0.9985\n","Epoch 16/20\n","32/32 [==============================] - 3s 88ms/step - loss: 2.5755e-04 - acc: 1.0000\n","Epoch 17/20\n","32/32 [==============================] - 3s 89ms/step - loss: 2.1902e-04 - acc: 1.0000\n","Epoch 18/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0020 - acc: 0.9997\n","Epoch 19/20\n","32/32 [==============================] - 3s 88ms/step - loss: 1.6015e-04 - acc: 1.0000\n","Epoch 20/20\n","32/32 [==============================] - 3s 88ms/step - loss: 3.3479e-04 - acc: 0.9997\n","Epoch 1/20\n","32/32 [==============================] - 6s 87ms/step - loss: 0.3713 - acc: 0.8536\n","Epoch 2/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0650 - acc: 0.9780\n","Epoch 3/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0335 - acc: 0.9900\n","Epoch 4/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0137 - acc: 0.9960\n","Epoch 5/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0155 - acc: 0.9967\n","Epoch 6/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0061 - acc: 0.9977\n","Epoch 7/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0045 - acc: 0.9980\n","Epoch 8/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0501 - acc: 0.9935\n","Epoch 9/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0583 - acc: 0.9880\n","Epoch 10/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0443 - acc: 0.9912\n","Epoch 11/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0679 - acc: 0.9842\n","Epoch 12/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0577 - acc: 0.9852\n","Epoch 13/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0545 - acc: 0.9837\n","Epoch 14/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0381 - acc: 0.9837\n","Epoch 15/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0129 - acc: 0.9960\n","Epoch 16/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0431 - acc: 0.9820\n","Epoch 17/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0073 - acc: 0.9995\n","Epoch 18/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0028 - acc: 1.0000\n","Epoch 19/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0031 - acc: 0.9997\n","Epoch 20/20\n","32/32 [==============================] - 3s 88ms/step - loss: 6.1257e-04 - acc: 0.9997\n","Epoch 1/20\n","32/32 [==============================] - 6s 87ms/step - loss: 0.3323 - acc: 0.8536\n","Epoch 2/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.5923 - acc: 0.7570\n","Epoch 3/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.2127 - acc: 0.9057\n","Epoch 4/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0276 - acc: 0.9915\n","Epoch 5/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0170 - acc: 0.9945\n","Epoch 6/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0105 - acc: 0.9970\n","Epoch 7/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0072 - acc: 0.9967\n","Epoch 8/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0039 - acc: 0.9980\n","Epoch 9/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0061 - acc: 0.9985\n","Epoch 10/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0018 - acc: 0.9995\n","Epoch 11/20\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0021 - acc: 0.9992\n","Epoch 12/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0013 - acc: 0.9992\n","Epoch 13/20\n","32/32 [==============================] - 3s 88ms/step - loss: 3.9378e-04 - acc: 1.0000\n","Epoch 14/20\n","32/32 [==============================] - 3s 89ms/step - loss: 7.9138e-04 - acc: 0.9997\n","Epoch 15/20\n","32/32 [==============================] - 3s 88ms/step - loss: 1.8273e-04 - acc: 1.0000\n","Epoch 16/20\n","32/32 [==============================] - 3s 88ms/step - loss: 4.1220e-04 - acc: 0.9997\n","Epoch 17/20\n","32/32 [==============================] - 3s 88ms/step - loss: 1.3457e-04 - acc: 1.0000\n","Epoch 18/20\n","32/32 [==============================] - 3s 89ms/step - loss: 8.1373e-05 - acc: 1.0000\n","Epoch 19/20\n","32/32 [==============================] - 3s 90ms/step - loss: 3.1568e-05 - acc: 1.0000\n","Epoch 20/20\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0028 - acc: 0.9997\n","LSTM corss validation :  0.9640 accuracy with a standard deviation of 0.0100\n"]}],"source":["\n","#98% B32 E20\n","#98% B64 E20\n","\n","from keras.layers.core import Flatten\n","\n","\n","\n","def create_keras_model():\n","\n","    model2 = Sequential()\n","    model2.add(Embedding(max_features, 128))\n","    model2.add(Dropout(0.5))\n","    model2.add(LSTM(128, return_sequences=True))\n","    model2.add(Dropout(0.5))\n","    model2.add(LSTM(128))\n","    model2.add(Dropout(0.2))\n","    model2.add(Dense(1, activation='sigmoid'))\n","    model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","\n","\n","    return model2\n","\n","\n","from keras.wrappers.scikit_learn import KerasClassifier\n","\n","LSTMmodel = KerasClassifier(\n","        build_fn=create_keras_model, \n","        batch_size=64, epochs=20)\n","\n","\n","LSTMmodel._estimator_type = \"classifier\"\n","\n","\n","\n","\n","\n","\n","from sklearn.model_selection import cross_val_score\n","accuracies_LSTM = cross_val_score(estimator=LSTMmodel, scoring=\"accuracy\", X=data, y=labels, cv=5)\n","\n","print(\"LSTM corss validation :  %0.4f accuracy with a standard deviation of %0.4f\" % (accuracies_LSTM.mean(), accuracies_LSTM.std()))"]},{"cell_type":"markdown","metadata":{"id":"uAiwbWGn_8VC"},"source":["128单层 b=1 e=20 98.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":627,"status":"ok","timestamp":1659200190110,"user":{"displayName":"B Hank","userId":"15763974084442005842"},"user_tz":-60},"id":"Q4-89ChX4wXn","outputId":"4748a74c-705c-43be-a189-5132e7e5def8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jul 30 16:56:27 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    33W / 250W |   4667MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LSTM.ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyMzlQwS4VzC2ZQjsS2OKrM0"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}